{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "import cv2\n",
    "import numpy as np\n",
    "import easyocr\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configure Gemini API\n",
    "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
    "if not GEMINI_API_KEY:\n",
    "    raise ValueError(\"GEMINI_API_KEY not found in .env file\")\n",
    "\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "# Initialize EasyOCR Reader\n",
    "ocr = easyocr.Reader(['en'])  # Supports English OCR\n",
    "\n",
    "\n",
    "def extract_text(pdf_path):\n",
    "    \"\"\"Extract text from a text-based PDF using PyMuPDF.\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "\n",
    "    for page in doc:\n",
    "        text += page.get_text(\"text\") + \"\\n\"  # Extract normal text\n",
    "        blocks = page.get_text(\"blocks\")  # Extract text from blocks (helps with columns)\n",
    "        \n",
    "        if blocks:\n",
    "            text += \"\\n\".join([b[4] for b in blocks if isinstance(b[4], str)]) + \"\\n\"\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def extract_text_ocr(pdf_path):\n",
    "    \"\"\"Use OCR to extract text from scanned/image-based PDFs.\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    extracted_text = []\n",
    "\n",
    "    for page_num, page in enumerate(doc):\n",
    "        pix = page.get_pixmap()  # Render page as an image\n",
    "        img = np.frombuffer(pix.samples, dtype=np.uint8).reshape(pix.h, pix.w, pix.n)\n",
    "\n",
    "        # Convert to grayscale for better OCR accuracy\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        results = ocr.readtext(gray)\n",
    "\n",
    "        # Extract recognized text\n",
    "        page_text = \" \".join([line[1] for line in results]) if results else \"\"\n",
    "        extracted_text.append(page_text)\n",
    "\n",
    "    return \"\\n\".join(extracted_text)\n",
    "\n",
    "\n",
    "def extract_images(pdf_path):\n",
    "    \"\"\"Extract images from a PDF and use OCR to get text from them.\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    extracted_text = []\n",
    "\n",
    "    for page_num, page in enumerate(doc):\n",
    "        for img_index, img in enumerate(page.get_images(full=True)):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "\n",
    "            # Extract image bytes\n",
    "            image_bytes = base_image.get(\"image\") or base_image.get(\"smask\", None)\n",
    "            if not image_bytes:\n",
    "                continue\n",
    "\n",
    "            # Convert bytes to OpenCV image\n",
    "            image = cv2.imdecode(np.frombuffer(image_bytes, np.uint8), cv2.IMREAD_COLOR)\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # Convert to grayscale for OCR\n",
    "\n",
    "            # Use EasyOCR for text extraction\n",
    "            results = ocr.readtext(gray)\n",
    "            page_text = \" \".join([line[1] for line in results]) if results else \"\"\n",
    "            extracted_text.append(page_text)\n",
    "\n",
    "    return extracted_text\n",
    "\n",
    "\n",
    "def analyze_pitch_deck(text, image_text):\n",
    "    \"\"\"Send extracted text to Gemini AI for analysis.\"\"\"\n",
    "    model = genai.GenerativeModel(\"gemini-pro\")  # Use \"gemini-pro-vision\" for images\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "        You are an expert in evaluating pitch decks. Analyze the following content:\n",
    "\n",
    "        - Extracted Text from the Pitch Deck: {text}\n",
    "        - Extracted Text from Graphs/Charts: {image_text}\n",
    "\n",
    "        Evaluate the pitch deck using the following criteria, scoring each from 1 to 25:\n",
    "\n",
    "        1. Problem & Solution Fit: (Score: __)\n",
    "        2. Market Potential & Business Model: (Score: __)\n",
    "        3. Traction & Competitive Edge: (Score: __)\n",
    "        4. Clarity & Presentation Quality: (Score: __)\n",
    "\n",
    "        Total Score: __/100\n",
    "\n",
    "        Summary (strictly one sentence): [Insight on strengths or weaknesses]\n",
    "\n",
    "        Only output the structured response. Avoid extra commentary.\n",
    "    \"\"\"\n",
    "\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text\n",
    "\n",
    "\n",
    "# Run the analysis\n",
    "pdf_path = r\"C:\\Users\\Administrator\\Downloads\\Pitch-Example-Air-BnB-PDF.pdf\"  # Change this to your PDF path\n",
    "\n",
    "# Extract text content (try standard method first, fallback to OCR)\n",
    "text_content = extract_text(pdf_path)\n",
    "if not text_content.strip():  # If no text found, use OCR\n",
    "    text_content = extract_text_ocr(pdf_path)\n",
    "\n",
    "# Extract text from images/graphs\n",
    "image_text = extract_images(pdf_path)\n",
    "\n",
    "# Analyze the pitch deck\n",
    "analysis = analyze_pitch_deck(text_content, image_text)\n",
    "\n",
    "# Print results\n",
    "print(\"üìú Extracted Text (First 500 chars):\\n\", text_content)\n",
    "print(\"\\nüìä Extracted Text from Graphs/Images:\\n\", image_text)\n",
    "print(\"\\nüîç Gemini AI Feedback:\\n\", analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load pre-trained BERT model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to preprocess text\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove special characters\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Function to extract sentiment score\n",
    "def get_sentiment(text):\n",
    "    return TextBlob(text).sentiment.polarity  # Range [-1,1]\n",
    "\n",
    "# Function to get BERT embeddings\n",
    "def get_bert_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()  # Mean pooling\n",
    "\n",
    "# Example pitch dataset (replace this with real data)\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"pitch_data_200.csv\")\n",
    "\n",
    "# Preprocess text\n",
    "df[\"processed_text\"] = df[\"pitch_text\"].apply(preprocess_text)\n",
    "\n",
    "# Extract features\n",
    "df[\"sentiment_score\"] = df[\"processed_text\"].apply(get_sentiment)\n",
    "vectorizer = TfidfVectorizer(max_features=100)\n",
    "X_tfidf = vectorizer.fit_transform(df[\"processed_text\"]).toarray()\n",
    "X_bert = np.array([get_bert_embeddings(text) for text in df[\"processed_text\"]])\n",
    "\n",
    "# Combine features\n",
    "X = np.hstack((X_tfidf, X_bert, df[\"sentiment_score\"].values.reshape(-1,1)))\n",
    "y = df[\"accepted\"]\n",
    "\n",
    "# Train model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save model\n",
    "joblib.dump(model, \"pitch_acceptance_model.pkl\")\n",
    "joblib.dump(vectorizer, \"tfidf_vectorizer.pkl\")\n",
    "\n",
    "# Function to predict pitch acceptance and give suggestions\n",
    "def predict_pitch(pitch_text):\n",
    "    processed_text = preprocess_text(pitch_text)\n",
    "    sentiment = get_sentiment(processed_text)\n",
    "    tfidf_features = vectorizer.transform([processed_text]).toarray()\n",
    "    bert_features = get_bert_embeddings(processed_text).reshape(1, -1)\n",
    "    features = np.hstack((tfidf_features, bert_features, np.array([[sentiment]])))\n",
    "\n",
    "    prediction = model.predict(features)[0]\n",
    "    probability = model.predict_proba(features)[0][1]\n",
    "\n",
    "    # Generate suggestions\n",
    "    suggestions = []\n",
    "    if sentiment < 0:\n",
    "        suggestions.append(\"Make the pitch more positive and persuasive.\")\n",
    "    if len(processed_text.split()) < 50:\n",
    "        suggestions.append(\"Provide more details about your business model.\")\n",
    "    if \"revenue\" not in pitch_text.lower():\n",
    "        suggestions.append(\"Include information about your revenue model.\")\n",
    "\n",
    "    return { \"probability\": probability, \"suggestions\": suggestions}\n",
    "\n",
    "# Example usage\n",
    "pitch_example = text_content\n",
    "result = predict_pitch(pitch_example)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
